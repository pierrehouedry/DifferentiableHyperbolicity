{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0bea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from hyperbolicity.tree_fitting_methods.hccfit import HccLinkage\n",
    "from hyperbolicity.tree_fitting_methods.tree_spanner import layering_approx_tree\n",
    "from hyperbolicity.tree_fitting_methods.treerep import TreeRep\n",
    "import networkx as nx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61deca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files(directory, output_file):\n",
    "    all_files = []\n",
    "    \n",
    "    # Traverse directory and subdirectories\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('hyperbolicity_results.csv'):\n",
    "                all_files.append(os.path.join(root, file))\n",
    "    \n",
    "    df_list = []\n",
    "\n",
    "    for file_path in all_files:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_list.append(df)\n",
    "\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f'Merged {len(all_files)} CSV files into {output_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c439b2f",
   "metadata": {},
   "source": [
    "# C-ELEGANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e11a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../datasets'\n",
    "\n",
    "airport = 'D_celegan.pkl'\n",
    "airport_path = os.path.join(base_path, airport)\n",
    "with open(airport_path, 'rb') as f:\n",
    "    distances = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2576e3",
   "metadata": {},
   "source": [
    "## Gromov and HDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3659c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged 1008 CSV files into /share/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/expes/results_expes/expe_celegan/results_celegan.csv\n"
     ]
    }
   ],
   "source": [
    "merge_csv_files('/share/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/expes/results_expes/expe_celegan', '/share/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/expes/results_expes/expe_celegan/results_celegan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef72572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/share/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/expes/results_expes/expe_celegan/results_celegan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a7414ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_epochs                         177\n",
       "intermediate_distortion     2.072127\n",
       "intermediate_l1             0.310326\n",
       "mean_optim_l1                0.41561\n",
       "min_optim_l1                0.403629\n",
       "std_optim_l1                  0.0106\n",
       "mean_no_optim_l1            1.136062\n",
       "min_no_optim_l1             1.026068\n",
       "std_no_optim_l1             0.036759\n",
       "mean_optim_distortion       1.838259\n",
       "min_optim_distortion         1.76303\n",
       "std_optim_distortion        0.057191\n",
       "mean_no_optim_distortion         3.3\n",
       "min_no_optim_distortion          3.0\n",
       "std_no_optim_distortion     0.458258\n",
       "run_number                         0\n",
       "dataset                      celegan\n",
       "learning_rate                    0.1\n",
       "distance_reg                     0.1\n",
       "scale_delta                     10.0\n",
       "epochs                           500\n",
       "batch_size                        32\n",
       "n_batches                        100\n",
       "gpu                             True\n",
       "Name: 989, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['mean_optim_distortion'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1871fa1",
   "metadata": {},
   "source": [
    "## HCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d074d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indices = np.random.choice(452, size=100, replace=False)\n",
    "N = distances.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a50a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8817505837568433 0.22667925078570564\n",
      "4.31 0.4624932431938871\n"
     ]
    }
   ],
   "source": [
    "l1 = []\n",
    "distortion = []\n",
    "denom = N*(N-1)\n",
    "for root in indices:\n",
    "    tree_hcc = HccLinkage(distances)\n",
    "    tree_hcc.fit_tree(root)\n",
    "    distortion.append(np.abs(tree_hcc.d_T-distances).max())\n",
    "    l1.append(np.abs(tree_hcc.d_T-distances).sum() / denom)\n",
    "\n",
    "print(np.mean(l1), np.std(l1))\n",
    "print(np.mean(distortion), np.std(distortion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2312540",
   "metadata": {},
   "source": [
    "## Layering Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bcf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "0.739044699095422 0.03490810432775373\n",
      "5.07 0.2551470164434615\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/share/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/datasets/bio-celegans.csv')\n",
    "df['id1'] -= 1\n",
    "df['id2'] -= 1\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(df[['id1', 'id2']].values)\n",
    "l1 = []\n",
    "distortion = []\n",
    "denom = N*(N-1)\n",
    "for root in indices:\n",
    "    layering_tree = layering_approx_tree(G, root)\n",
    "    distance_layering = nx.floyd_warshall_numpy(layering_tree)\n",
    "    distortion.append(np.abs(distance_layering-distances).max())\n",
    "    l1.append(np.abs(distance_layering-distances).sum() / denom)\n",
    "print(np.mean(l1), np.std(l1))\n",
    "print(np.mean(distortion), np.std(distortion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89098f21",
   "metadata": {},
   "source": [
    "## TreeRep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e14218",
   "metadata": {},
   "source": [
    "# CS-PHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f2b40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../datasets'\n",
    "\n",
    "airport = 'D_csphd.pkl'\n",
    "airport_path = os.path.join(base_path, airport)\n",
    "with open(airport_path, 'rb') as f:\n",
    "    distances = pickle.load(f)\n",
    "distances = distances.astype(np.float64)\n",
    "\n",
    "np.random.seed(42)\n",
    "N = distances.shape[0]\n",
    "indices = np.random.choice(N, size=100, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40997831",
   "metadata": {},
   "source": [
    "## HCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5fc66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5996860899390244 1.1140393019427608\n",
      "23.35 2.075451758051726\n"
     ]
    }
   ],
   "source": [
    "l1 = []\n",
    "distortion = []\n",
    "denom = N*(N-1)\n",
    "for root in indices:\n",
    "    tree_hcc = HccLinkage(distances)\n",
    "    tree_hcc.fit_tree(root)\n",
    "    distortion.append(np.abs(tree_hcc.d_T-distances).max())\n",
    "    l1.append(np.abs(tree_hcc.d_T-distances).sum() / denom)\n",
    "\n",
    "print(np.mean(l1), np.std(l1))\n",
    "print(np.mean(distortion), np.std(distortion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb87679",
   "metadata": {},
   "source": [
    "## Layering Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0cafb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.265081897865855 0.4943979995513763\n",
      "25.48 0.6079473661428266\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/share/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/datasets/ca-CSphd.csv')\n",
    "df['id1'] -= 1\n",
    "df['id2'] -= 1\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(df[['id1', 'id2']].values)\n",
    "l1 = []\n",
    "distortion = []\n",
    "denom = N*(N-1)\n",
    "for root in indices:\n",
    "    layering_tree = layering_approx_tree(G, root)\n",
    "    distance_layering = nx.floyd_warshall_numpy(layering_tree)\n",
    "    distortion.append(np.abs(distance_layering-distances).max())\n",
    "    l1.append(np.abs(distance_layering-distances).sum() / denom)\n",
    "print(np.mean(l1), np.std(l1))\n",
    "print(np.mean(distortion), np.std(distortion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb87b3",
   "metadata": {},
   "source": [
    "# Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dd51b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../datasets'\n",
    "\n",
    "airport = 'D_cora.pkl'\n",
    "airport_path = os.path.join(base_path, airport)\n",
    "with open(airport_path, 'rb') as f:\n",
    "    distances = pickle.load(f)\n",
    "distances = distances.astype(np.float64)\n",
    "\n",
    "np.random.seed(42)\n",
    "N = distances.shape[0]\n",
    "indices = np.random.choice(N, size=100, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50ae31b",
   "metadata": {},
   "source": [
    "## HCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2c88b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4474343938024283 0.4383590871665283\n",
      "12.28 0.96\n"
     ]
    }
   ],
   "source": [
    "l1 = []\n",
    "distortion = []\n",
    "denom = N*(N-1)\n",
    "for root in indices:\n",
    "    tree_hcc = HccLinkage(distances)\n",
    "    tree_hcc.fit_tree(root)\n",
    "    distortion.append(np.abs(tree_hcc.d_T-distances).max())\n",
    "    l1.append(np.abs(tree_hcc.d_T-distances).sum() / denom)\n",
    "\n",
    "print(np.mean(l1), np.std(l1))\n",
    "print(np.mean(distortion), np.std(distortion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab93313",
   "metadata": {},
   "source": [
    "## Layering Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2e8354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "G = to_networkx(data, to_undirected=True)\n",
    "largest_cc_nodes = max(nx.connected_components(G), key=len)\n",
    "G_lcc = G.subgraph(largest_cc_nodes).copy()\n",
    "np.random.seed(42)\n",
    "N = G_lcc.number_of_nodes()\n",
    "indices = np.random.choice(N, size=100, replace=False)\n",
    "distances = nx.floyd_warshall_numpy(G_lcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42aa52fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2485 is out of bounds for axis 0 with size 2485",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m denom = N*(N-\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m root \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     layering_tree = \u001b[43mlayering_approx_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_lcc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     distance_layering = nx.floyd_warshall_numpy(layering_tree)\n\u001b[32m      7\u001b[39m     distortion.append(np.abs(distance_layering-distances).max())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/castor/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/tree_fitting_methods/tree_spanner.py:32\u001b[39m, in \u001b[36mlayering_approx_tree\u001b[39m\u001b[34m(graph, source)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlayering_approx_tree\u001b[39m(graph, source):\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     partition = \u001b[43mlayering_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     T = nx.Graph()\n\u001b[32m     34\u001b[39m     T.add_nodes_from(graph.nodes())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/castor/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/tree_fitting_methods/tree_spanner.py:16\u001b[39m, in \u001b[36mlayering_partition\u001b[39m\u001b[34m(graph, source)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlayering_partition\u001b[39m(graph, source):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     layers = \u001b[43mlayering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     dist = nx.floyd_warshall_numpy(graph)\n\u001b[32m     18\u001b[39m     partition = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/castor/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/tree_fitting_methods/tree_spanner.py:11\u001b[39m, in \u001b[36mlayering\u001b[39m\u001b[34m(graph, source)\u001b[39m\n\u001b[32m      9\u001b[39m layers = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph.nodes():\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     d = \u001b[43mdist\u001b[49m\u001b[43m[\u001b[49m\u001b[43msource\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m     layers[d].append(node)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m layers\n",
      "\u001b[31mIndexError\u001b[39m: index 2485 is out of bounds for axis 0 with size 2485"
     ]
    }
   ],
   "source": [
    "l1 = []\n",
    "distortion = []\n",
    "denom = N*(N-1)\n",
    "for root in indices:\n",
    "    layering_tree = layering_approx_tree(G_lcc, root)\n",
    "    distance_layering = nx.floyd_warshall_numpy(layering_tree)\n",
    "    distortion.append(np.abs(distance_layering-distances).max())\n",
    "    l1.append(np.abs(distance_layering-distances).sum() / denom)\n",
    "print(np.mean(l1), np.std(l1))\n",
    "print(np.mean(distortion), np.std(distortion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059135b",
   "metadata": {},
   "source": [
    "# Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e29c6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../datasets'\n",
    "\n",
    "airport = 'D_airport.pkl'\n",
    "airport_path = os.path.join(base_path, airport)\n",
    "with open(airport_path, 'rb') as f:\n",
    "    distances = pickle.load(f)\n",
    "distances = distances.astype(np.float64)\n",
    "\n",
    "np.random.seed(42)\n",
    "N = distances.shape[0]\n",
    "indices = np.random.choice(N, size=100, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1361e",
   "metadata": {},
   "source": [
    "## HCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dca8540c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1059447896980141 0.13988059753483872\n",
      "7.71 0.7251896303726358\n"
     ]
    }
   ],
   "source": [
    "l1 = []\n",
    "distortion = []\n",
    "denom = N*(N-1)\n",
    "for root in indices:\n",
    "    tree_hcc = HccLinkage(distances)\n",
    "    tree_hcc.fit_tree(root)\n",
    "    distortion.append(np.abs(tree_hcc.d_T-distances).max())\n",
    "    l1.append(np.abs(tree_hcc.d_T-distances).sum() / denom)\n",
    "\n",
    "print(np.mean(l1), np.std(l1))\n",
    "print(np.mean(distortion), np.std(distortion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ac4076",
   "metadata": {},
   "source": [
    "## Layering Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eacb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_cc_nodes = max(nx.connected_components(G), key=len)\n",
    "G_lcc = G.subgraph(largest_cc_nodes).copy()\n",
    "np.random.seed(42)\n",
    "N = G_lcc.number_of_nodes()\n",
    "indices = np.random.choice(N, size=100, replace=False)\n",
    "distances = nx.floyd_warshall_numpy(G_lcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd160669",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "distortion = []\n",
    "denom = N*(N-1)\n",
    "for root in indices:\n",
    "    layering_tree = layering_approx_tree(G_lcc, root)\n",
    "    distance_layering = nx.floyd_warshall_numpy(layering_tree)\n",
    "    distortion.append(np.abs(distance_layering-distances).max())\n",
    "    l1.append(np.abs(distance_layering-distances).sum() / denom)\n",
    "print(np.mean(l1), np.std(l1))\n",
    "print(np.mean(distortion), np.std(distortion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90987002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged 108 CSV files into /share/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/expes/results_expes/expe_phd/results_phd.csv\n"
     ]
    }
   ],
   "source": [
    "merge_csv_files('/share/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/expes/results_expes/expe_phd', '/share/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/expes/results_expes/expe_phd/results_phd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9cb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/share/home/houedry/projects/DifferentiableHyperbolicity/hyperbolicity/expes/results_expes/expe_phd/results_phd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c975d776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_epochs                         500\n",
       "intermediate_distortion     8.674208\n",
       "intermediate_l1             1.035947\n",
       "mean_optim_l1               1.276931\n",
       "min_optim_l1                1.177544\n",
       "std_optim_l1                0.046907\n",
       "mean_optim_distortion      10.150798\n",
       "min_optim_distortion        9.467228\n",
       "std_optim_distortion        0.489663\n",
       "run_number                         0\n",
       "dataset                          phd\n",
       "learning_rate                    0.1\n",
       "distance_reg                     0.1\n",
       "scale_delta                     10.0\n",
       "epochs                           500\n",
       "batch_size                        32\n",
       "n_batches                        100\n",
       "gpu                             True\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['mean_optim_distortion'].idxmin()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyperenv_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
