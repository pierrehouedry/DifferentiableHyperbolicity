{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbebcfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import torch\n",
    "import networkx as nx\n",
    "from hyperbolicity.utils import create_log_dir, setup_logger, str2bool, soft_max, datasp, sample_batch_indices, batched_datasp_submatrices, construct_weighted_matrix, make_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9821d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance as ssd\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "def linkage_to_distance_matrix(Z):\n",
    "    \"\"\"\n",
    "    Converts a linkage matrix Z (from scipy.cluster.hierarchy.linkage)\n",
    "    into a full pairwise distance matrix D of shape (n, n), where n is the number of leaves.\n",
    "    \"\"\"\n",
    "    N = Z.shape[0] + 1\n",
    "    clusters = [[i] for i in range(N)]\n",
    "    D = np.zeros((N, N))\n",
    "    for i in range(N - 1):\n",
    "        j, k = int(Z[i, 0]), int(Z[i, 1])\n",
    "        for x in clusters[j]:\n",
    "            for y in clusters[k]:\n",
    "                D[x, y] = D[y, x] = Z[i, 2]\n",
    "        clusters.append(clusters[j] + clusters[k])\n",
    "    return D\n",
    "\n",
    "def gromov_tree(distance_matrix, root):\n",
    "    \"\"\"\n",
    "    Computes a Gromov-style distance matrix from a given root using a hierarchical clustering\n",
    "    approximation based on the induced ultrametric.\n",
    "\n",
    "    Parameters:\n",
    "        distance_matrix (np.ndarray): Original pairwise distance matrix.\n",
    "        root (int): Index to use as the root node.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Gromov-adjusted distance matrix (tree-metric approximation).\n",
    "    \"\"\"\n",
    "    n = distance_matrix.shape[0]\n",
    "    d_root = distance_matrix[root]\n",
    "    d_max = d_root.max()\n",
    "    \n",
    "    gp = np.tile(d_root, (n, 1)) + np.tile(d_root.reshape(n, 1), (1, n)) - distance_matrix\n",
    "    gp /= 2.0\n",
    "\n",
    "    d_U = d_max - gp\n",
    "    np.fill_diagonal(d_U, 0)\n",
    "\n",
    "    Z = linkage(ssd.squareform(d_U), method='single')\n",
    "    D_gromov = linkage_to_distance_matrix(Z)\n",
    "\n",
    "    gp_T = d_max - D_gromov\n",
    "    d_T = np.tile(d_root, (n, 1)) + np.tile(d_root.reshape(n, 1), (1, n)) - 2.0 * gp_T\n",
    "    np.fill_diagonal(d_T, 0)\n",
    "\n",
    "    return d_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb49dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/share/home/houedry/projects/hyperbolic/DifferentiableHyperbolicity/hyperbolicity/datasets'\n",
    "\n",
    "c_elegan = 'D_celegan.pkl'\n",
    "c_elegan_path = os.path.join(base_path, c_elegan)\n",
    "with open(c_elegan_path, 'rb') as f:\n",
    "    distances = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(distances, weights):\n",
    "    num_nodes = distances.shape[0]\n",
    "    edges = torch.triu_indices(num_nodes, num_nodes, offset=1)\n",
    "    optimum = construct_weighted_matrix(weights, num_nodes, edges)\n",
    "    G = nx.from_numpy_array(optimum.numpy())\n",
    "    intermediate_distances = nx.floyd_warshall_numpy(G)\n",
    "    mean_optim = []\n",
    "    mean_no_optim = []\n",
    "    for j in range(num_nodes):\n",
    "        tree_optim = gromov_tree(intermediate_distances, j)\n",
    "        mean_optim.append(np.abs(tree_optim-distances).max())\n",
    "        \n",
    "\n",
    "    return np.mean(mean_optim), np.min(mean_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "618b78c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Starting experiment scan ==\n",
      "Looking in: /share/home/houedry/projects/hyperbolic/DifferentiableHyperbolicity/hyperbolicity/results_expes/expe_test/expe_celegan/expe_celegan/\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_18_02_04-run_number-4-dataset-celegan-learning_rate-0.5-distance_reg-0.0001-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.327450295201445\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.3273908426012615\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.327221460574496\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_19_21_41-run_number-2-dataset-celegan-learning_rate-1.0-distance_reg-0.0001-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.3274866602325863\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_19_51_50-run_number-2-dataset-celegan-learning_rate-1.0-distance_reg-0.5-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.327513556037329\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_18_28_09-run_number-3-dataset-celegan-learning_rate-0.5-distance_reg-0.01-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.327274818995358\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.3264148472684676\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.332075940428582\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_18_28_09-run_number-1-dataset-celegan-learning_rate-0.5-distance_reg-0.1-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.327453214642221\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_19_51_40-run_number-0-dataset-celegan-learning_rate-1.0-distance_reg-0.001-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.3291936663136017\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.6058863573553106\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_18_02_04-run_number-3-dataset-celegan-learning_rate-0.5-distance_reg-0.001-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_18_02_04-run_number-0-dataset-celegan-learning_rate-0.5-distance_reg-0.0001-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.327398072301814\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_18_02_08-run_number-3-dataset-celegan-learning_rate-0.5-distance_reg-0.0001-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.3262106557335476\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.329051136179308\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.3276341434864873\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_18_28_09-run_number-4-dataset-celegan-learning_rate-0.5-distance_reg-0.01-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "[WARN] Failed to process res.pickle in launch_distance_hyperbolicity_learning_2025_04_15_19_51_40-run_number-4-dataset-celegan-learning_rate-1.0-distance_reg-0.01-scale_sp-10000.0-scale_delta-10000.0-scale_softmax-10000.0-epochs-500-batch_size-32: 'float' object has no attribute 'device'\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.3272958760504174\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.328683161498171\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.329507061074265\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.3273770396424607\n",
      "    → Computing metrics...\n",
      "    → m1 = 3.3281142145922753\n",
      "    → Computing metrics...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    → Computing metrics...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     m1\u001b[38;5;241m=\u001b[39m compute_metrics(distances, weights)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    → m1 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m     results_dict[config_key]\u001b[38;5;241m.\u001b[39mappend(m1)\n",
      "Cell \u001b[0;32mIn[33], line 10\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(distances, weights)\u001b[0m\n\u001b[1;32m      8\u001b[0m mean_no_optim \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_nodes):\n\u001b[0;32m---> 10\u001b[0m     tree_optim \u001b[38;5;241m=\u001b[39m gromov_tree(intermediate_distances, j)\n\u001b[1;32m     11\u001b[0m     mean_optim\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mabs(tree_optim\u001b[38;5;241m-\u001b[39mdistances)\u001b[38;5;241m.\u001b[39mmax())\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(mean_optim)\n",
      "Cell \u001b[0;32mIn[11], line 37\u001b[0m, in \u001b[0;36mgromov_tree\u001b[0;34m(distance_matrix, root)\u001b[0m\n\u001b[1;32m     34\u001b[0m np\u001b[38;5;241m.\u001b[39mfill_diagonal(d_U, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     36\u001b[0m Z \u001b[38;5;241m=\u001b[39m linkage(ssd\u001b[38;5;241m.\u001b[39msquareform(d_U), method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m D_gromov \u001b[38;5;241m=\u001b[39m linkage_to_distance_matrix(Z)\n\u001b[1;32m     39\u001b[0m gp_T \u001b[38;5;241m=\u001b[39m d_max \u001b[38;5;241m-\u001b[39m D_gromov\n\u001b[1;32m     40\u001b[0m d_T \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(d_root, (n, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(d_root\u001b[38;5;241m.\u001b[39mreshape(n, \u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m1\u001b[39m, n)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m gp_T\n",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m, in \u001b[0;36mlinkage_to_distance_matrix\u001b[0;34m(Z)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m clusters[j]:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m clusters[k]:\n\u001b[0;32m---> 20\u001b[0m             D[x, y] \u001b[38;5;241m=\u001b[39m D[y, x] \u001b[38;5;241m=\u001b[39m Z[i, \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     21\u001b[0m     clusters\u001b[38;5;241m.\u001b[39mappend(clusters[j] \u001b[38;5;241m+\u001b[39m clusters[k])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m D\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_path = '/share/home/houedry/projects/hyperbolic/DifferentiableHyperbolicity/hyperbolicity/results_expes/expe_test/expe_celegan/expe_celegan/'\n",
    "\n",
    "def extract_config_key(folder_name):\n",
    "    return re.sub(r'-run_number-\\d+', '', folder_name)\n",
    "\n",
    "results_dict = defaultdict(list)\n",
    "\n",
    "print(\"== Starting experiment scan ==\")\n",
    "print(f\"Looking in: {base_path}\")\n",
    "\n",
    "for folder in os.listdir(base_path):\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    if os.path.isdir(folder_path) and folder.startswith('launch_distance_hyperbolicity_learning'):\n",
    "        config_key = extract_config_key(folder)\n",
    "\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file == \"res.pickle\":\n",
    "                with open(os.path.join(folder_path, file), 'rb') as f:\n",
    "                    weights = pickle.load(f)['weights']\n",
    "                    try:\n",
    "                        print(f\"    → Computing metrics...\")\n",
    "                        m1= compute_metrics(distances, weights)\n",
    "                        print(f\"    → m1 = {m1}\")\n",
    "                        results_dict[config_key].append(m1)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[WARN] Failed to process {file} in {folder}: {e}\")\n",
    "\n",
    "if not results_dict:\n",
    "    print(\"No results collected. Please double-check path, file names, and formats.\")\n",
    "else:\n",
    "    print(\"Results collected! Printing aggregated metrics:\\n\")\n",
    "\n",
    "for config, values in results_dict.items():\n",
    "    values = np.array(values)\n",
    "    mean_metrics = np.mean(values, axis=0)\n",
    "    std_metrics = np.std(values, axis=0)\n",
    "    \n",
    "    print(f\"{config}\")\n",
    "    print(f\"\\tMetric 1 -> Mean: {mean_metrics[0]:.4f}, Std: {std_metrics[0]:.4f}\")\n",
    "    print(f\"\\tMetric 2 -> Mean: {mean_metrics[1]:.4f}, Std: {std_metrics[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278815c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
